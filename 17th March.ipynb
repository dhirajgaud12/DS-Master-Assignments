{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Missing values in a dataset are of the type Missing completely at random, Missing at random and Missing not at random. It is essential to handle missing values because otherwise it will create biased models.  K-nearest and Naive Bayes are not affected by missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is mean imputation\n",
      " 0      22.000000\n",
      "1      38.000000\n",
      "2      26.000000\n",
      "3      35.000000\n",
      "4      35.000000\n",
      "         ...    \n",
      "886    27.000000\n",
      "887    19.000000\n",
      "888    29.699118\n",
      "889    26.000000\n",
      "890    32.000000\n",
      "Name: Age_mean, Length: 891, dtype: float64\n",
      "this is fare median imputation\n",
      " 0       7.2500\n",
      "1      71.2833\n",
      "2       7.9250\n",
      "3      53.1000\n",
      "4       8.0500\n",
      "        ...   \n",
      "886    13.0000\n",
      "887    30.0000\n",
      "888    23.4500\n",
      "889    30.0000\n",
      "890     7.7500\n",
      "Name: faremedian, Length: 891, dtype: float64\n",
      "this is sex mode imputation\n",
      " 0        male\n",
      "1      female\n",
      "2      female\n",
      "3      female\n",
      "4        male\n",
      "        ...  \n",
      "886      male\n",
      "887    female\n",
      "888    female\n",
      "889      male\n",
      "890      male\n",
      "Name: sexmode, Length: 891, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2) Missing data handling techniques - Mean imputation,Median imputation and Mode imputation. \n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    " \n",
    "\n",
    "titanicdf = sns.load_dataset('titanic')\n",
    "titanicdf['Age_mean']=titanicdf['age'].fillna(titanicdf['age'].mean())\n",
    "print(\"this is mean imputation\\n\",titanicdf['Age_mean'])\n",
    "\n",
    "\n",
    "titanicdf['faremedian']=titanicdf['fare'].fillna(titanicdf['fare'].median())\n",
    "print(\"this is fare median imputation\\n\",titanicdf['faremedian'])\n",
    "\n",
    "titanicdf['sexmode']=titanicdf['sex'].fillna(titanicdf['sex'].mode())\n",
    "print(\"this is sex mode imputation\\n\",titanicdf['sexmode'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Imbalance data is when we have more number of rows for particular columns or features. If we dont handle imbalance data then it will create innacuracy in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Up sampling is when we balance a dataset feature by filling values into the na rows and this technique preserves the data. Down sampling is when we remove the rows from a feature but this reduces the accuracy of the dataset. We use upsampling to preserve the data and we use downsampling when the data to be removed is not going to cause major accuracy changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. Synthetic minority over sampling technique is technique used for filling the missing data points by filling data by extrapolating the points between 2 instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Outliers in a dataset are datapoints which vary hugely from the other datapoints. Outliers cause inaccurate results in models as they vary hugely from the other datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) We can use SMOTE if missing data is continuous and non categorical. We can use mean,median imputation where we have data with numerical values and we can use mode for categorical data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Conduct statistical tests to formally assess whether the missing data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). We can use MCAR test, multiple imputation methods,  Exploratory Data Analysis, Missing Data Heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) We can use feature engineering to handle imbalance dataset. Carefully choose and engineer features that are more informative for the minority class. This might involve consulting domain experts to identify relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) We can use Synthetic Minority Over-sampling Technique (SMOTE) with Under-sampling and balanced Balanced Subsampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) For oversampling we can use SMOTE (Synthetic Minority Over-sampling Technique),Random Over-sampling with Replacement, Cluster-Based Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
